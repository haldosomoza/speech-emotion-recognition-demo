{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Souce: https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\n",
    "Other Sources:\n",
    "- https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio/data\n",
    "- https://gitlab.fhnw.ch/manuel.wullschleger/milproject/-/blob/master/Dokumentation.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy scikit-learn librosa soundfile pyaudio imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython;   \n",
    "get_ipython().magic('reset -sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import soundfile \n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "\n",
    "#Ignore warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "SEED = 80\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            #mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#DataFlair - Emotions to observe\n",
    "observed_emotions=['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "observed_emotions=['neutral', 'calm', 'happy', 'angry'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"../00_training_dataset/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion_code = file_name.split(\"-\")[2]\n",
    "        emotion=emotions[emotion_code]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        print(file, \"->\", emotion_code, \"=\", emotion)\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../00_training_dataset\\Actor_01\\03-01-01-01-01-01-01.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_01\\03-01-01-01-01-02-01.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_01\\03-01-01-01-02-01-01.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_01\\03-01-01-01-02-02-01.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_01\\03-01-02-01-01-01-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-01-01-02-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-01-02-01-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-01-02-02-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-02-01-01-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-02-01-02-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-02-02-01-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-02-02-02-02-01.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_01\\03-01-03-01-01-01-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-01-01-02-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-01-02-01-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-01-02-02-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-02-01-01-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-02-01-02-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-02-02-01-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-03-02-02-02-01.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_01\\03-01-05-01-01-01-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-01-01-02-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-01-02-01-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-01-02-02-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-02-01-01-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-02-01-02-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-02-02-01-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_01\\03-01-05-02-02-02-01.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-01-01-01-01-02.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_02\\03-01-01-01-01-02-02.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_02\\03-01-01-01-02-01-02.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_02\\03-01-01-01-02-02-02.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_02\\03-01-02-01-01-01-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-01-01-02-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-01-02-01-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-01-02-02-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-02-01-01-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-02-01-02-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-02-02-01-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-02-02-02-02-02.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_02\\03-01-03-01-01-01-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-01-01-02-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-01-02-01-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-01-02-02-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-02-01-01-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-02-01-02-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-02-02-01-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-03-02-02-02-02.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_02\\03-01-05-01-01-01-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-01-01-02-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-01-02-01-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-01-02-02-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-02-01-01-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-02-01-02-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-02-02-01-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_02\\03-01-05-02-02-02-02.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-01-01-01-01-03.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_03\\03-01-01-01-01-02-03.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_03\\03-01-01-01-02-01-03.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_03\\03-01-01-01-02-02-03.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_03\\03-01-02-01-01-01-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-01-01-02-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-01-02-01-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-01-02-02-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-02-01-01-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-02-01-02-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-02-02-01-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-02-02-02-02-03.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_03\\03-01-03-01-01-01-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-01-01-02-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-01-02-01-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-01-02-02-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-02-01-01-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-02-01-02-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-02-02-01-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-03-02-02-02-03.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_03\\03-01-05-01-01-01-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-01-01-02-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-01-02-01-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-01-02-02-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-02-01-01-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-02-01-02-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-02-02-01-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_03\\03-01-05-02-02-02-03.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-01-01-01-01-04.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_04\\03-01-01-01-01-02-04.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_04\\03-01-01-01-02-01-04.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_04\\03-01-01-01-02-02-04.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_04\\03-01-02-01-01-01-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-01-01-02-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-01-02-01-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-01-02-02-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-02-01-01-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-02-01-02-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-02-02-01-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-02-02-02-02-04.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_04\\03-01-03-01-01-01-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-01-01-02-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-01-02-01-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-01-02-02-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-02-01-01-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-02-01-02-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-02-02-01-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-03-02-02-02-04.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_04\\03-01-05-01-01-01-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-01-01-02-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-01-02-01-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-01-02-02-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-02-01-01-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-02-01-02-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-02-02-01-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_04\\03-01-05-02-02-02-04.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-01-01-01-01-05.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_05\\03-01-01-01-01-02-05.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_05\\03-01-01-01-02-01-05.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_05\\03-01-01-01-02-02-05.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_05\\03-01-02-01-01-01-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-01-01-02-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-01-02-01-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-01-02-02-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-02-01-01-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-02-01-02-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-02-02-01-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-02-02-02-02-05.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_05\\03-01-03-01-01-01-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-01-01-02-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-01-02-01-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-01-02-02-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-02-01-01-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-02-01-02-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-02-02-01-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-03-02-02-02-05.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_05\\03-01-05-01-01-01-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-01-01-02-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-01-02-01-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-01-02-02-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-02-01-01-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-02-01-02-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-02-02-01-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_05\\03-01-05-02-02-02-05.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-01-01-01-01-06.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_06\\03-01-01-01-01-02-06.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_06\\03-01-01-01-02-01-06.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_06\\03-01-01-01-02-02-06.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_06\\03-01-02-01-01-01-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-01-01-02-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-01-02-01-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-01-02-02-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-02-01-01-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-02-01-02-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-02-02-01-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-02-02-02-02-06.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_06\\03-01-03-01-01-01-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-01-01-02-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-01-02-01-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-01-02-02-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-02-01-01-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-02-01-02-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-02-02-01-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-03-02-02-02-06.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_06\\03-01-05-01-01-01-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-01-01-02-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-01-02-01-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-01-02-02-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-02-01-01-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-02-01-02-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-02-02-01-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_06\\03-01-05-02-02-02-06.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-01-01-01-01-07.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_07\\03-01-01-01-01-02-07.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_07\\03-01-01-01-02-01-07.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_07\\03-01-01-01-02-02-07.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_07\\03-01-02-01-01-01-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-01-01-02-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-01-02-01-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-01-02-02-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-02-01-01-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-02-01-02-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-02-02-01-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-02-02-02-02-07.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_07\\03-01-03-01-01-01-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-01-01-02-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-01-02-01-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-01-02-02-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-02-01-01-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-02-01-02-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-02-02-01-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-03-02-02-02-07.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_07\\03-01-05-01-01-01-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-01-01-02-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-01-02-01-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-01-02-02-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-02-01-01-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-02-01-02-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-02-02-01-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_07\\03-01-05-02-02-02-07.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-01-01-01-01-08.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_08\\03-01-01-01-01-02-08.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_08\\03-01-01-01-02-01-08.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_08\\03-01-01-01-02-02-08.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_08\\03-01-02-01-01-01-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-01-01-02-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-01-02-01-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-01-02-02-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-02-01-01-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-02-01-02-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-02-02-01-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-02-02-02-02-08.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_08\\03-01-03-01-01-01-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-01-01-02-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-01-02-01-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-01-02-02-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-02-01-01-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-02-01-02-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-02-02-01-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-03-02-02-02-08.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_08\\03-01-05-01-01-01-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-01-01-02-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-01-02-01-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-01-02-02-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-02-01-01-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-02-01-02-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-02-02-01-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_08\\03-01-05-02-02-02-08.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-01-01-01-01-09.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_09\\03-01-01-01-01-02-09.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_09\\03-01-01-01-02-01-09.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_09\\03-01-01-01-02-02-09.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_09\\03-01-02-01-01-01-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-01-01-02-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-01-02-01-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-01-02-02-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-02-01-01-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-02-01-02-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-02-02-01-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-02-02-02-02-09.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_09\\03-01-03-01-01-01-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-01-01-02-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-01-02-01-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-01-02-02-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-02-01-01-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-02-01-02-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-02-02-01-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-03-02-02-02-09.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_09\\03-01-05-01-01-01-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-01-01-02-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-01-02-01-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-01-02-02-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-02-01-01-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-02-01-02-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-02-02-01-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_09\\03-01-05-02-02-02-09.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-01-01-01-01-10.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_10\\03-01-01-01-01-02-10.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_10\\03-01-01-01-02-01-10.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_10\\03-01-01-01-02-02-10.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_10\\03-01-02-01-01-01-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-01-01-02-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-01-02-01-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-01-02-02-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-02-01-01-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-02-01-02-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-02-02-01-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-02-02-02-02-10.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_10\\03-01-03-01-01-01-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-01-01-02-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-01-02-01-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-01-02-02-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-02-01-01-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-02-01-02-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-02-02-01-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-03-02-02-02-10.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_10\\03-01-05-01-01-01-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-01-01-02-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-01-02-01-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-01-02-02-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-02-01-01-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-02-01-02-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-02-02-01-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_10\\03-01-05-02-02-02-10.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-01-01-01-01-11.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_11\\03-01-01-01-01-02-11.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_11\\03-01-01-01-02-01-11.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_11\\03-01-01-01-02-02-11.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_11\\03-01-02-01-01-01-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-01-01-02-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-01-02-01-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-01-02-02-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-02-01-01-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-02-01-02-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-02-02-01-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-02-02-02-02-11.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_11\\03-01-03-01-01-01-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-01-01-02-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-01-02-01-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-01-02-02-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-02-01-01-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-02-01-02-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-02-02-01-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-03-02-02-02-11.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_11\\03-01-05-01-01-01-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-01-01-02-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-01-02-01-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-01-02-02-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-02-01-01-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-02-01-02-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-02-02-01-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_11\\03-01-05-02-02-02-11.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-01-01-01-01-12.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_12\\03-01-01-01-01-02-12.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_12\\03-01-01-01-02-01-12.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_12\\03-01-01-01-02-02-12.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_12\\03-01-02-01-01-01-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-01-01-02-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-01-02-01-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-01-02-02-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-02-01-01-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-02-01-02-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-02-02-01-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-02-02-02-02-12.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_12\\03-01-03-01-01-01-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-01-01-02-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-01-02-01-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-01-02-02-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-02-01-01-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-02-01-02-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-02-02-01-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-03-02-02-02-12.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_12\\03-01-05-01-01-01-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-01-01-02-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-01-02-01-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-01-02-02-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-02-01-01-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-02-01-02-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-02-02-01-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_12\\03-01-05-02-02-02-12.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-01-01-01-01-13.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_13\\03-01-01-01-01-02-13.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_13\\03-01-01-01-02-01-13.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_13\\03-01-01-01-02-02-13.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_13\\03-01-02-01-01-01-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-01-01-02-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-01-02-01-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-01-02-02-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-02-01-01-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-02-01-02-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-02-02-01-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-02-02-02-02-13.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_13\\03-01-03-01-01-01-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-01-01-02-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-01-02-01-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-01-02-02-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-02-01-01-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-02-01-02-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-02-02-01-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-03-02-02-02-13.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_13\\03-01-05-01-01-01-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-01-01-02-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-01-02-01-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-01-02-02-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-02-01-01-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-02-01-02-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-02-02-01-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_13\\03-01-05-02-02-02-13.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-01-01-01-01-14.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_14\\03-01-01-01-01-02-14.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_14\\03-01-01-01-02-01-14.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_14\\03-01-01-01-02-02-14.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_14\\03-01-02-01-01-01-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-01-01-02-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-01-02-01-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-01-02-02-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-02-01-01-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-02-01-02-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-02-02-01-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-02-02-02-02-14.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_14\\03-01-03-01-01-01-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-01-01-02-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-01-02-01-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-01-02-02-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-02-01-01-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-02-01-02-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-02-02-01-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-03-02-02-02-14.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_14\\03-01-05-01-01-01-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-01-01-02-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-01-02-01-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-01-02-02-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-02-01-01-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-02-01-02-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-02-02-01-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_14\\03-01-05-02-02-02-14.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-01-01-01-01-15.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_15\\03-01-01-01-01-02-15.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_15\\03-01-01-01-02-01-15.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_15\\03-01-01-01-02-02-15.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_15\\03-01-02-01-01-01-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-01-01-02-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-01-02-01-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-01-02-02-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-02-01-01-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-02-01-02-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-02-02-01-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-02-02-02-02-15.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_15\\03-01-03-01-01-01-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-01-01-02-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-01-02-01-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-01-02-02-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-02-01-01-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-02-01-02-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-02-02-01-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-03-02-02-02-15.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_15\\03-01-05-01-01-01-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-01-01-02-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-01-02-01-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-01-02-02-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-02-01-01-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-02-01-02-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-02-02-01-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_15\\03-01-05-02-02-02-15.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-01-01-01-01-16.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_16\\03-01-01-01-01-02-16.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_16\\03-01-01-01-02-01-16.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_16\\03-01-01-01-02-02-16.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_16\\03-01-02-01-01-01-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-01-01-02-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-01-02-01-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-01-02-02-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-02-01-01-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-02-01-02-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-02-02-01-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-02-02-02-02-16.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_16\\03-01-03-01-01-01-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-01-01-02-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-01-02-01-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-01-02-02-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-02-01-01-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-02-01-02-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-02-02-01-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-03-02-02-02-16.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_16\\03-01-05-01-01-01-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-01-01-02-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-01-02-01-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-01-02-02-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-02-01-01-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-02-01-02-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-02-02-01-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_16\\03-01-05-02-02-02-16.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-01-01-01-01-17.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_17\\03-01-01-01-01-02-17.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_17\\03-01-01-01-02-01-17.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_17\\03-01-01-01-02-02-17.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_17\\03-01-02-01-01-01-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-01-01-02-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-01-02-01-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-01-02-02-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-02-01-01-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-02-01-02-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-02-02-01-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-02-02-02-02-17.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_17\\03-01-03-01-01-01-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-01-01-02-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-01-02-01-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-01-02-02-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-02-01-01-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-02-01-02-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-02-02-01-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-03-02-02-02-17.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_17\\03-01-05-01-01-01-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-01-01-02-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-01-02-01-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-01-02-02-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-02-01-01-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-02-01-02-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-02-02-01-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_17\\03-01-05-02-02-02-17.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-01-01-01-01-18.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_18\\03-01-01-01-01-02-18.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_18\\03-01-01-01-02-01-18.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_18\\03-01-01-01-02-02-18.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_18\\03-01-02-01-01-01-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-01-01-02-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-01-02-01-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-01-02-02-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-02-01-01-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-02-01-02-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-02-02-01-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-02-02-02-02-18.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_18\\03-01-03-01-01-01-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-01-01-02-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-01-02-01-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-01-02-02-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-02-01-01-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-02-01-02-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-02-02-01-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-03-02-02-02-18.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_18\\03-01-05-01-01-01-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-01-01-02-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-01-02-01-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-01-02-02-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-02-01-01-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-02-01-02-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-02-02-01-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_18\\03-01-05-02-02-02-18.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-01-01-01-01-19.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_19\\03-01-01-01-01-02-19.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_19\\03-01-01-01-02-01-19.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_19\\03-01-01-01-02-02-19.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_19\\03-01-02-01-01-01-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-01-01-02-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-01-02-01-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-01-02-02-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-02-01-01-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-02-01-02-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-02-02-01-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-02-02-02-02-19.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_19\\03-01-03-01-01-01-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-01-01-02-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-01-02-01-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-01-02-02-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-02-01-01-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-02-01-02-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-02-02-01-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-03-02-02-02-19.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_19\\03-01-05-01-01-01-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-01-01-02-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-01-02-01-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-01-02-02-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-02-01-01-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-02-01-02-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-02-02-01-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_19\\03-01-05-02-02-02-19.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-01-01-01-01-20.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_20\\03-01-01-01-01-02-20.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_20\\03-01-01-01-02-01-20.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_20\\03-01-01-01-02-02-20.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_20\\03-01-02-01-01-01-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-01-01-02-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-01-02-01-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-01-02-02-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-02-01-01-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-02-01-02-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-02-02-01-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-02-02-02-02-20.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_20\\03-01-03-01-01-01-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-01-01-02-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-01-02-01-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-01-02-02-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-02-01-01-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-02-01-02-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-02-02-01-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-03-02-02-02-20.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_20\\03-01-05-01-01-01-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-01-01-02-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-01-02-01-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-01-02-02-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-02-01-01-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-02-01-02-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-02-02-01-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_20\\03-01-05-02-02-02-20.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-01-01-01-01-21.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_21\\03-01-01-01-01-02-21.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_21\\03-01-01-01-02-01-21.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_21\\03-01-01-01-02-02-21.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_21\\03-01-02-01-01-01-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-01-01-02-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-01-02-01-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-01-02-02-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-02-01-01-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-02-01-02-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-02-02-01-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-02-02-02-02-21.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_21\\03-01-03-01-01-01-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-01-01-02-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-01-02-01-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-01-02-02-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-02-01-01-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-02-01-02-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-02-02-01-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-03-02-02-02-21.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_21\\03-01-05-01-01-01-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-01-01-02-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-01-02-01-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-01-02-02-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-02-01-01-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-02-01-02-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-02-02-01-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_21\\03-01-05-02-02-02-21.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-01-01-01-01-22.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_22\\03-01-01-01-01-02-22.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_22\\03-01-01-01-02-01-22.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_22\\03-01-01-01-02-02-22.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_22\\03-01-02-01-01-01-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-01-01-02-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-01-02-01-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-01-02-02-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-02-01-01-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-02-01-02-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-02-02-01-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-02-02-02-02-22.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_22\\03-01-03-01-01-01-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-01-01-02-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-01-02-01-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-01-02-02-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-02-01-01-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-02-01-02-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-02-02-01-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-03-02-02-02-22.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_22\\03-01-05-01-01-01-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-01-01-02-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-01-02-01-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-01-02-02-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-02-01-01-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-02-01-02-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-02-02-01-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_22\\03-01-05-02-02-02-22.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-01-01-01-01-23.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_23\\03-01-01-01-01-02-23.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_23\\03-01-01-01-02-01-23.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_23\\03-01-01-01-02-02-23.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_23\\03-01-02-01-01-01-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-01-01-02-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-01-02-01-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-01-02-02-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-02-01-01-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-02-01-02-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-02-02-01-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-02-02-02-02-23.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_23\\03-01-03-01-01-01-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-01-01-02-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-01-02-01-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-01-02-02-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-02-01-01-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-02-01-02-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-02-02-01-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-03-02-02-02-23.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_23\\03-01-05-01-01-01-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-01-01-02-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-01-02-01-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-01-02-02-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-02-01-01-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-02-01-02-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-02-02-01-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_23\\03-01-05-02-02-02-23.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-01-01-01-01-24.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_24\\03-01-01-01-01-02-24.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_24\\03-01-01-01-02-01-24.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_24\\03-01-01-01-02-02-24.wav -> 01 = neutral\n",
      "../00_training_dataset\\Actor_24\\03-01-02-01-01-01-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-01-01-02-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-01-02-01-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-01-02-02-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-02-01-01-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-02-01-02-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-02-02-01-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-02-02-02-02-24.wav -> 02 = calm\n",
      "../00_training_dataset\\Actor_24\\03-01-03-01-01-01-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-01-01-02-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-01-02-01-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-01-02-02-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-02-01-01-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-02-01-02-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-02-02-01-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-03-02-02-02-24.wav -> 03 = happy\n",
      "../00_training_dataset\\Actor_24\\03-01-05-01-01-01-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-01-01-02-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-01-02-01-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-01-02-02-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-02-01-01-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-02-01-02-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-02-02-01-24.wav -> 05 = angry\n",
      "../00_training_dataset\\Actor_24\\03-01-05-02-02-02-24.wav -> 05 = angry\n",
      "CPU times: total: 4.44 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#DataFlair - Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 135)\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy      155\n",
      "calm       154\n",
      "angry      154\n",
      "neutral     74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3 Chek dataset balance \n",
    "emotion_counts = pd.Series(y_train).value_counts()\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot spectrograms\n",
    "def plot_spectrogram(data, emotion, sr=22050):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    S = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_DB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram for {emotion}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a random file for each observed emotion and plot the spectrogram\n",
    "for emotion in observed_emotions:\n",
    "    # Find files corresponding to the emotion\n",
    "    files = [file for file in glob.glob(\"./01-speech-emotion-data/Actor_*/*.wav\") if emotions[os.path.basename(file).split(\"-\")[2]] == emotion]\n",
    "    \n",
    "    if files:\n",
    "        # Select a random file\n",
    "        file_path = np.random.choice(files)\n",
    "        \n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(file_path)\n",
    "        \n",
    "        # Plot the spectogram\n",
    "        plot_spectrogram(y, emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAHWCAYAAAB9mLjgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGyklEQVR4nO3deVyVZf7/8fdBEBAExBREEXBJ0dxSM9LKhcJdyzLKMXVcMlfUypxyyUlNc3csy5lwGW1Xx1IZFbdMNMWh0sgRw6UUaTJALBHh/v3Rj/vbCVFuZDno6/l43I+H93Vd57o/94GD533u5dgMwzAEAAAAACg0p7IuAAAAAADKG4IUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFIBybdq0abLZbKWyrfbt26t9+/bm+q5du2Sz2fTRRx+VyvYHDhyo4ODgUtlWUWVmZmrIkCHy9/eXzWZTVFRUWZdULBz5uV+xYoVsNptOnjxZ1qUUWt5rZ9euXZYfe/LkSdlsNq1YsaLY6wIAKwhSABxG3hvCvMXNzU0BAQGKiIjQ4sWLdfHixWLZztmzZzVt2jQlJCQUy3zFyZFrK4yZM2dqxYoVevbZZ7V69Wr179+/wLHBwcF2P+/fL507dy7Fqn9T3p/74jBw4MACfya/XwYOHFjWpZaZkydPatCgQapbt67c3Nzk7++vBx54QFOnTi3SfJs3b9a0adOKt0gApcJmGIZR1kUAgPRbkBo0aJCmT5+ukJAQZWdnKyUlRbt27dK2bdtUu3Ztbdy4UU2bNjUfc/XqVV29elVubm6F3s6hQ4fUunVrRUdHW3pDeOXKFUlSxYoVJf32qXqHDh304Ycf6rHHHiv0PEWtLTs7W7m5uXJ1dS2WbZWEe++9V87Oztq7d+8NxwYHB6tKlSqaMGFCvr6AgAB17NixJEosUHl97nNycpSdnS1XV9ebPjobFxenEydOmOvJycmaMmWKhg0bpvvvv99sr1u3rsLCwoq8ndzcXF25ckUVK1aUk5O1z3QNw1BWVpZcXFxUoUKFItdQFElJSWrdurXc3d315z//WcHBwTp37pwOHz6sLVu26PLly5bnHDVqlJYuXSrejgHlj3NZFwAAf9SlSxe1atXKXJ80aZJ27Nih7t27q2fPnkpMTJS7u7skydnZWc7OJfun7JdfflGlSpXMAFVWXFxcynT7hZGamqpGjRoVenzNmjX1pz/9qQQrKh6O/NxXqFCh2AJFWFiYXUA6dOiQpkyZorCwsOv+nC5duiQPD49Cb8fJycnShx+/l3e0uiwsWLBAmZmZSkhIUFBQkF1fampqmdQEoOxwah+AcqFjx46aPHmyTp06pX/+859m+7Wukdq2bZvatWsnHx8feXp6qkGDBvrLX/4i6bejSK1bt5YkDRo0yDxVKe96i/bt2+uuu+5SfHy8HnjgAVWqVMl87B+vkcqTk5Ojv/zlL/L395eHh4d69uypM2fO2I0JDg6+5tGv3895o9qudZ3OpUuXNGHCBAUGBsrV1VUNGjTQ3Llz8326bbPZNGrUKG3YsEF33XWXXF1d1bhxY8XExFz7Cf+D1NRUDR48WH5+fnJzc1OzZs20cuVKsz/vmpfk5GRt2rTJrL04rtsZOHCgPD09dfr0aXXv3l2enp6qWbOmli5dKkn6+uuv1bFjR3l4eCgoKEhr167NN8d3332nxx9/XL6+vqpUqZLuvfdebdq0ya7+sn7uL168qKioKAUHB8vV1VXVq1fXQw89pMOHD1/3+bnWNVLBwcHq3r279u7dq3vuuUdubm6qU6eOVq1add25CiNve7t379aIESNUvXp11apVS5J06tQpjRgxQg0aNJC7u7uqVq2qxx9/PN/vwbWukcp77X3zzTfq0KGDKlWqpJo1a2rOnDl2j73WNVJ5vyM//PCDevfuLU9PT1WrVk3PPfeccnJy7B7/008/qX///vLy8pKPj48GDBigL7/8slDXXZ04cUK1atXKF6IkqXr16vnatmzZovvvv18eHh6qXLmyunXrpqNHj9rVnfd7/PtTJwGUDwQpAOVG3vU2W7duLXDM0aNH1b17d2VlZWn69OmaN2+eevbsqc8//1ySFBoaqunTp0uShg0bptWrV2v16tV64IEHzDl++ukndenSRc2bN9fChQvVoUOH69Y1Y8YMbdq0SRMnTtSYMWO0bds2hYeH69dff7W0f4Wp7fcMw1DPnj21YMECde7cWfPnz1eDBg30/PPPa/z48fnG7927VyNGjFBkZKTmzJmjy5cvq0+fPvrpp5+uW9evv/6q9u3ba/Xq1erXr59ef/11eXt7a+DAgVq0aJFZ++rVq3XHHXeoefPmZu3VqlW77tzZ2dn63//+l2/543OXk5OjLl26KDAwUHPmzFFwcLBGjRqlFStWqHPnzmrVqpVmz56typUr6+mnn1ZycrL52PPnz+u+++7Tv//9b40YMUIzZszQ5cuX1bNnT61fv95hnvvhw4frzTffVJ8+ffTGG2/oueeek7u7uxITE6/7HBYkKSlJjz32mB566CHNmzdPVapU0cCBA+3eyN+MESNG6JtvvtGUKVP04osvSpIOHjyoffv2KTIyUosXL9bw4cMVGxur9u3b65dffrnhnD///LM6d+6sZs2aad68eWrYsKEmTpyoLVu23PCxOTk5ioiIUNWqVTV37lw9+OCDmjdvnt5++21zTG5urnr06KF3331XAwYM0IwZM3Tu3DkNGDCgUPscFBSkM2fOaMeOHTccu3r1anXr1k2enp6aPXu2Jk+erG+++Ubt2rUzg+Uzzzyjhx56yByftwAoJwwAcBDR0dGGJOPgwYMFjvH29jZatGhhrk+dOtX4/Z+yBQsWGJKMH3/8scA5Dh48aEgyoqOj8/U9+OCDhiRj2bJl1+x78MEHzfWdO3cakoyaNWsaGRkZZvsHH3xgSDIWLVpktgUFBRkDBgy44ZzXq23AgAFGUFCQub5hwwZDkvHqq6/ajXvssccMm81mJCUlmW2SjIoVK9q1ffnll4YkY8mSJfm29XsLFy40JBn//Oc/zbYrV64YYWFhhqenp92+BwUFGd26dbvufL8fK+may6xZs+z2W5Ixc+ZMs+3nn3823N3dDZvNZrz33ntm+7fffmtIMqZOnWq2RUVFGZKMzz77zGy7ePGiERISYgQHBxs5OTmGYZT9c+/t7W2MHDmyEM+cvbzXTXJystmW99zu2bPHbEtNTTVcXV2NCRMmFHruaz0nedtr166dcfXqVbvxv/zyS7454uLiDEnGqlWrzLa8187OnTvNtrzX3u/HZWVlGf7+/kafPn3MtuTk5Hw15f2OTJ8+3W7bLVq0MFq2bGmuf/zxx4YkY+HChWZbTk6O0bFjxwJ/9r935MgRw93d3ZBkNG/e3Bg7dqyxYcMG49KlS3bjLl68aPj4+BhDhw61a09JSTG8vb3t2keOHGn3NwxA+cERKQDliqen53Xv3ufj4yNJ+te//qXc3NwibcPV1VWDBg0q9Pinn35alStXNtcfe+wx1ahRQ5s3by7S9gtr8+bNqlChgsaMGWPXPmHCBBmGke9T/PDwcNWtW9dcb9q0qby8vPTdd9/dcDv+/v568sknzTYXFxeNGTNGmZmZ2r17d5H3oU2bNtq2bVu+5ffbyjNkyBDz3z4+PmrQoIE8PDzUt29fs71Bgwby8fGx26fNmzfrnnvuUbt27cw2T09PDRs2TCdPntQ333xjue6SeO59fHx04MABnT171nI919KoUSO7G0RUq1ZNDRo0uOHPu7CGDh2a79qsvGsXpd+ONv7000+qV6+efHx8bniKovTbz+X312JVrFhR99xzT6FrHj58uN36/fffb/fYmJgYubi4aOjQoWabk5OTRo4cWaj5GzdurISEBP3pT3/SyZMntWjRIvXu3Vt+fn5avny5OW7btm1KS0vTk08+aXektUKFCmrTpo127txZqO0BcGwEKQDlSmZmpl1o+aMnnnhCbdu21ZAhQ+Tn56fIyEh98MEHlkJVzZo1Ld1Yon79+nbrNptN9erVK/Hv9Tl16pQCAgLyPR+hoaFm/+/Vrl073xxVqlTRzz//fMPt1K9fP9/d1QrajhV33HGHwsPD8y1/vAbFzc0t32mC3t7eqlWrVr5rSry9ve326dSpU2rQoEG+bd9M/SXx3M+ZM0dHjhxRYGCg7rnnHk2bNu2mQk9Rf96FFRISkq/t119/1ZQpU8zrxu644w5Vq1ZNaWlpSk9Pv+Gc1/p5Frbma/2O/PGxp06dUo0aNVSpUiW7cfXq1bvh/HnuvPNOrV69Wv/73//01VdfaebMmXJ2dtawYcO0fft2SdLx48cl/XZtZ7Vq1eyWrVu3cmMK4BbBXfsAlBvff/+90tPTr/umx93dXXv27NHOnTu1adMmxcTE6P3331fHjh21devWQt3d7PefqheXgi4gz8nJKbVbOBe0HaMc3Ha5oNrLyz4Vps6+ffvq/vvv1/r167V161a9/vrrmj17ttatW6cuXbqUyDZvxrVeJ6NHj1Z0dLSioqIUFhYmb29v2Ww2RUZGFurDjJupubRvhV6hQgU1adJETZo0UVhYmDp06KA1a9YoPDzc3NfVq1fL398/32NL+k6jAEoHr2QA5UbeRdgRERHXHefk5KROnTqpU6dOmj9/vmbOnKmXXnpJO3fuVHh4eLHfFSvv0+c8hmEoKSnJ7vuuqlSporS0tHyPPXXqlOrUqWOuW6ktKChI27dv18WLF+2OjHz77bdmf3EICgrSV199pdzcXLujUsW9nZISFBSkY8eO5Wv/Y/2O8NzXqFFDI0aM0IgRI5Samqq7775bM2bMKFKQKgsfffSRBgwYoHnz5pltly9fvubvflkICgrSzp07za80yJOUlHRT8+Z9XcO5c+ckyTyNs3r16goPD7/uY7lLH1B+cWofgHJhx44d+utf/6qQkBD169evwHEXLlzI19a8eXNJUlZWliSZ33dTXG/uVq1aZXfd1kcffaRz587ZvfmtW7eu9u/fb36pryR9+umn+W6TbqW2rl27KicnR3/729/s2hcsWCCbzVZsb767du2qlJQUvf/++2bb1atXtWTJEnl6eurBBx8slu2UlK5du+qLL75QXFyc2Xbp0iW9/fbbCg4ONr/3qiyf+5ycnHynvlWvXl0BAQHm7215UKFChXxHj5YsWZLvFuRlJSIiQtnZ2XbXM+Xm5pq3IL+Rzz77TNnZ2fna866HzDuFNCIiQl5eXpo5c+Y1x//444/mv4v77xGA0sMRKQAOZ8uWLfr222919epVnT9/Xjt27NC2bdsUFBSkjRs3XvfLOKdPn649e/aoW7duCgoKUmpqqt544w3VqlXLvNlA3bp15ePjo2XLlqly5cry8PBQmzZtrnnNR2H4+vqqXbt2GjRokM6fP6+FCxeqXr16dhe0DxkyRB999JE6d+6svn376sSJE/rnP/9pdwMCq7X16NFDHTp00EsvvaSTJ0+qWbNm2rp1q/71r38pKioq39xFNWzYML311lsaOHCg4uPjFRwcrI8++kiff/65Fi5ceN1r1m7khx9+sPtesDyenp7q3bv3TVT9f1588UW9++676tKli8aMGSNfX1+tXLlSycnJ+vjjj82jbGX53F+8eFG1atXSY489pmbNmsnT01Pbt2/XwYMH7Y7uOLru3btr9erV8vb2VqNGjRQXF6ft27eratWqZV2aJKl379665557NGHCBCUlJalhw4bauHGj+QHMjY4OzZ49W/Hx8Xr00UfNI86HDx/WqlWr5Ovrq6ioKEmSl5eX3nzzTfXv31933323IiMjVa1aNZ0+fVqbNm1S27ZtzRDesmVLSdKYMWMUERGhChUqKDIysoSeAQDFiSAFwOFMmTJF0m937PL19VWTJk20cOFCDRo06IZv2nv27KmTJ0/qnXfe0f/+9z/dcccdevDBB/XKK6/I29tb0m93nFu5cqUmTZqk4cOH6+rVq4qOji5ykPrLX/6ir776SrNmzdLFixfVqVMnvfHGG3anDkVERGjevHmaP3++oqKi1KpVK3366aeaMGGC3VxWanNyctLGjRs1ZcoUvf/++4qOjlZwcLBef/31fPPeDHd3d+3atUsvvviiVq5cqYyMDDVo0EDR0dHX/JJhKxISEszvB/u9oKCgYgtSfn5+2rdvnyZOnKglS5bo8uXLatq0qT755BN169bNHFeWz32lSpU0YsQIbd26VevWrVNubq7q1aunN954Q88+++xN7X9pWrRokSpUqKA1a9bo8uXLatu2rbZv337D03FLS4UKFbRp0yaNHTtWK1eulJOTkx555BFNnTpVbdu2ve6HNNJvr/W1a9dq9+7dWrNmjX755RfVqFFDkZGRmjx5st3vylNPPaWAgAC99tprev3115WVlaWaNWvq/vvvt7sr6KOPPqrRo0frvffe0z//+U8ZhkGQAsoJm+FoV+QCAACUog0bNuiRRx7R3r171bZt27IuB0A5QZACAAC3jV9//dXujoM5OTl6+OGHdejQIaWkpJTIXTsB3Jo4tQ8AANw2Ro8erV9//VVhYWHKysrSunXrtG/fPs2cOZMQBcASjkgBAIDbxtq1azVv3jwlJSXp8uXLqlevnp599lmNGjWqrEsDUM4QpAAAAADAIr5HCgAAAAAsIkgBAAAAgEXcbEK/fav52bNnVbly5Rt+GR8AAACAW5dhGLp48aICAgLML22/FoKUpLNnzyowMLCsywAAAADgIM6cOaNatWoV2E+QklS5cmVJvz1ZXl5eZVwNAAAAgLKSkZGhwMBAMyMUpEyD1J49e/T6668rPj5e586d0/r169W7d2+7MYmJiZo4caJ2796tq1evqlGjRvr4449Vu3ZtSdLly5c1YcIEvffee8rKylJERITeeOMN+fn5FbqOvNP5vLy8CFIAAAAAbnjJT5nebOLSpUtq1qyZli5des3+EydOqF27dmrYsKF27dqlr776SpMnT5abm5s5Zty4cfrkk0/04Ycfavfu3Tp79qweffTR0toFAAAAALchh/keKZvNlu+IVGRkpFxcXLR69eprPiY9PV3VqlXT2rVr9dhjj0mSvv32W4WGhiouLk733ntvobadkZEhb29vpaenc0QKAAAAuI0VNhs47O3Pc3NztWnTJt15552KiIhQ9erV1aZNG23YsMEcEx8fr+zsbIWHh5ttDRs2VO3atRUXF1fg3FlZWcrIyLBbAAAAAKCwHDZIpaamKjMzU6+99po6d+6srVu36pFHHtGjjz6q3bt3S5JSUlJUsWJF+fj42D3Wz89PKSkpBc49a9YseXt7mwt37AMAAABghcMGqdzcXElSr169NG7cODVv3lwvvviiunfvrmXLlt3U3JMmTVJ6erq5nDlzpjhKBgAAAHCbcNjbn99xxx1ydnZWo0aN7NpDQ0O1d+9eSZK/v7+uXLmitLQ0u6NS58+fl7+/f4Fzu7q6ytXVtUTqBgAAAHDrc9gjUhUrVlTr1q117Ngxu/b//ve/CgoKkiS1bNlSLi4uio2NNfuPHTum06dPKywsrFTrBQAAAHD7KNMjUpmZmUpKSjLXk5OTlZCQIF9fX9WuXVvPP/+8nnjiCT3wwAPq0KGDYmJi9Mknn2jXrl2SJG9vbw0ePFjjx4+Xr6+vvLy8NHr0aIWFhRX6jn0AAAAAYFWZ3v58165d6tChQ772AQMGaMWKFZKkd955R7NmzdL333+vBg0a6JVXXlGvXr3MsXlfyPvuu+/afSHv9U7t+yNufw4AAABAKnw2cJjvkSpLBCkAAAAA0i3wPVIAAAAA4KgIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCoTL9H6lbV8vlVZV0CbhPxrz9d1iUAAADcljgiBQAAAAAWcUQKQIngyCxKiyMfmeV1gNLiyK8D4FbFESkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIvKNEjt2bNHPXr0UEBAgGw2mzZs2FDg2OHDh8tms2nhwoV27RcuXFC/fv3k5eUlHx8fDR48WJmZmSVbOAAAAIDbWpkGqUuXLqlZs2ZaunTpdcetX79e+/fvV0BAQL6+fv366ejRo9q2bZs+/fRT7dmzR8OGDSupkgEAAABAzmW58S5duqhLly7XHfPDDz9o9OjR+ve//61u3brZ9SUmJiomJkYHDx5Uq1atJElLlixR165dNXfu3GsGLwAAAAC4WQ59jVRubq769++v559/Xo0bN87XHxcXJx8fHzNESVJ4eLicnJx04MCBAufNyspSRkaG3QIAAAAAheXQQWr27NlydnbWmDFjrtmfkpKi6tWr27U5OzvL19dXKSkpBc47a9YseXt7m0tgYGCx1g0AAADg1uawQSo+Pl6LFi3SihUrZLPZinXuSZMmKT093VzOnDlTrPMDAAAAuLU5bJD67LPPlJqaqtq1a8vZ2VnOzs46deqUJkyYoODgYEmSv7+/UlNT7R539epVXbhwQf7+/gXO7erqKi8vL7sFAAAAAAqrTG82cT39+/dXeHi4XVtERIT69++vQYMGSZLCwsKUlpam+Ph4tWzZUpK0Y8cO5ebmqk2bNqVeMwAAAIDbQ5kGqczMTCUlJZnrycnJSkhIkK+vr2rXrq2qVavajXdxcZG/v78aNGggSQoNDVXnzp01dOhQLVu2TNnZ2Ro1apQiIyO5Yx8AAACAElOmp/YdOnRILVq0UIsWLSRJ48ePV4sWLTRlypRCz7FmzRo1bNhQnTp1UteuXdWuXTu9/fbbJVUyAAAAAJTtEan27dvLMIxCjz958mS+Nl9fX61du7YYqwIAAACA63PYm00AAAAAgKMiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABaVaZDas2ePevTooYCAANlsNm3YsMHsy87O1sSJE9WkSRN5eHgoICBATz/9tM6ePWs3x4ULF9SvXz95eXnJx8dHgwcPVmZmZinvCQAAAIDbSZkGqUuXLqlZs2ZaunRpvr5ffvlFhw8f1uTJk3X48GGtW7dOx44dU8+ePe3G9evXT0ePHtW2bdv06aefas+ePRo2bFhp7QIAAACA25BzWW68S5cu6tKlyzX7vL29tW3bNru2v/3tb7rnnnt0+vRp1a5dW4mJiYqJidHBgwfVqlUrSdKSJUvUtWtXzZ07VwEBASW+DwAAAABuP+XqGqn09HTZbDb5+PhIkuLi4uTj42OGKEkKDw+Xk5OTDhw4UOA8WVlZysjIsFsAAAAAoLDKTZC6fPmyJk6cqCeffFJeXl6SpJSUFFWvXt1unLOzs3x9fZWSklLgXLNmzZK3t7e5BAYGlmjtAAAAAG4t5SJIZWdnq2/fvjIMQ2+++eZNzzdp0iSlp6eby5kzZ4qhSgAAAAC3izK9Rqow8kLUqVOntGPHDvNolCT5+/srNTXVbvzVq1d14cIF+fv7Fzinq6urXF1dS6xmAAAAALc2hz4ilReijh8/ru3bt6tq1ap2/WFhYUpLS1N8fLzZtmPHDuXm5qpNmzalXS4AAACA20SZHpHKzMxUUlKSuZ6cnKyEhAT5+vqqRo0aeuyxx3T48GF9+umnysnJMa978vX1VcWKFRUaGqrOnTtr6NChWrZsmbKzszVq1ChFRkZyxz4AAAAAJaZMg9ShQ4fUoUMHc338+PGSpAEDBmjatGnauHGjJKl58+Z2j9u5c6fat28vSVqzZo1GjRqlTp06ycnJSX369NHixYtLpX4AAAAAt6cyDVLt27eXYRgF9l+vL4+vr6/Wrl1bnGUBAAAAwHU59DVSAAAAAOCICFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFZRqk9uzZox49eiggIEA2m00bNmyw6zcMQ1OmTFGNGjXk7u6u8PBwHT9+3G7MhQsX1K9fP3l5ecnHx0eDBw9WZmZmKe4FAAAAgNtNmQapS5cuqVmzZlq6dOk1++fMmaPFixdr2bJlOnDggDw8PBQREaHLly+bY/r166ejR49q27Zt+vTTT7Vnzx4NGzastHYBAAAAwG3IuSw33qVLF3Xp0uWafYZhaOHChXr55ZfVq1cvSdKqVavk5+enDRs2KDIyUomJiYqJidHBgwfVqlUrSdKSJUvUtWtXzZ07VwEBAaW2LwAAAABuHw57jVRycrJSUlIUHh5utnl7e6tNmzaKi4uTJMXFxcnHx8cMUZIUHh4uJycnHThwoMC5s7KylJGRYbcAAAAAQGE5bJBKSUmRJPn5+dm1+/n5mX0pKSmqXr26Xb+zs7N8fX3NMdcya9YseXt7m0tgYGAxVw8AAADgVuawQaokTZo0Senp6eZy5syZsi4JAAAAQDnisEHK399fknT+/Hm79vPnz5t9/v7+Sk1Nteu/evWqLly4YI65FldXV3l5edktAAAAAFBYDhukQkJC5O/vr9jYWLMtIyNDBw4cUFhYmCQpLCxMaWlpio+PN8fs2LFDubm5atOmTanXDAAAAOD2UKZ37cvMzFRSUpK5npycrISEBPn6+qp27dqKiorSq6++qvr16yskJESTJ09WQECAevfuLUkKDQ1V586dNXToUC1btkzZ2dkaNWqUIiMjuWMfAAAAgBJTpkHq0KFD6tChg7k+fvx4SdKAAQO0YsUKvfDCC7p06ZKGDRumtLQ0tWvXTjExMXJzczMfs2bNGo0aNUqdOnWSk5OT+vTpo8WLF5f6vgAAAAC4fZRpkGrfvr0Mwyiw32azafr06Zo+fXqBY3x9fbV27dqSKA8AAAAArslhr5ECAAAAAEdFkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYFGRglSdOnX0008/5WtPS0tTnTp1brooAAAAAHBkRQpSJ0+eVE5OTr72rKws/fDDDzddFAAAAAA4Mmcrgzdu3Gj++9///re8vb3N9ZycHMXGxio4OLjYigMAAAAAR2QpSPXu3VuSZLPZNGDAALs+FxcXBQcHa968ecVWHAAAAAA4IktBKjc3V5IUEhKigwcP6o477iiRogAAAADAkVkKUnmSk5OLuw4AAAAAKDeKFKQkKTY2VrGxsUpNTTWPVOV55513browAAAAAHBURQpSr7zyiqZPn65WrVqpRo0astlsxV0XAAAAADisIgWpZcuWacWKFerfv39x1wMAAAAADq9I3yN15coV3XfffcVdCwAAAACUC0UKUkOGDNHatWuLuxYAAAAAKBeKdGrf5cuX9fbbb2v79u1q2rSpXFxc7Prnz59fLMUBAAAAgCMqUpD66quv1Lx5c0nSkSNH7Pq48QQAAACAW12RgtTOnTuLuw4AAAAAKDeKdI0UAAAAANzOinREqkOHDtc9hW/Hjh1FLggAAAAAHF2RglTe9VF5srOzlZCQoCNHjmjAgAHFURcAAAAAOKwiBakFCxZcs33atGnKzMy8qYIAAAAAwNEV6zVSf/rTn/TOO+8U23w5OTmaPHmyQkJC5O7urrp16+qvf/2rDMMwxxiGoSlTpqhGjRpyd3dXeHi4jh8/Xmw1AAAAAMAfFWuQiouLk5ubW7HNN3v2bL355pv629/+psTERM2ePVtz5szRkiVLzDFz5szR4sWLtWzZMh04cEAeHh6KiIjQ5cuXi60OAAAAAPi9Ip3a9+ijj9qtG4ahc+fO6dChQ5o8eXKxFCZJ+/btU69evdStWzdJUnBwsN5991198cUX5nYXLlyol19+Wb169ZIkrVq1Sn5+ftqwYYMiIyOvOW9WVpaysrLM9YyMjGKrGQAAAMCtr0hHpLy9ve0WX19ftW/fXps3b9bUqVOLrbj77rtPsbGx+u9//ytJ+vLLL7V371516dJFkpScnKyUlBSFh4fb1damTRvFxcUVOO+sWbPs6g8MDCy2mgEAAADc+op0RCo6Orq467imF198URkZGWrYsKEqVKignJwczZgxQ/369ZMkpaSkSJL8/PzsHufn52f2XcukSZM0fvx4cz0jI4MwBQAAAKDQihSk8sTHxysxMVGS1LhxY7Vo0aJYisrzwQcfaM2aNVq7dq0aN26shIQERUVFKSAg4KZus+7q6ipXV9dirBQAAADA7aRIQSo1NVWRkZHatWuXfHx8JElpaWnq0KGD3nvvPVWrVq1Yinv++ef14osvmtc6NWnSRKdOndKsWbM0YMAA+fv7S5LOnz+vGjVqmI87f/58vu+6AgAAAIDiUqRrpEaPHq2LFy/q6NGjunDhgi5cuKAjR44oIyNDY8aMKbbifvnlFzk52ZdYoUIF5ebmSpJCQkLk7++v2NhYsz8jI0MHDhxQWFhYsdUBAAAAAL9XpCNSMTEx2r59u0JDQ822Ro0aaenSpXr44YeLrbgePXpoxowZql27tho3bqz//Oc/mj9/vv785z9Lkmw2m6KiovTqq6+qfv36CgkJ0eTJkxUQEKDevXsXWx0AAAAA8HtFClK5ublycXHJ1+7i4mIeLSoOS5Ys0eTJkzVixAilpqYqICBAzzzzjKZMmWKOeeGFF3Tp0iUNGzZMaWlpateunWJiYor1+6wAAAAA4PeKFKQ6duyosWPH6t1331VAQIAk6YcfftC4cePUqVOnYiuucuXKWrhwoRYuXFjgGJvNpunTp2v69OnFtl0AAAAAuJ4iXSP1t7/9TRkZGQoODlbdunVVt25dhYSEKCMjQ0uWLCnuGgEAAADAoRTpiFRgYKAOHz6s7du369tvv5UkhYaG2n0xLgAAAADcqiwdkdqxY4caNWqkjIwM2Ww2PfTQQxo9erRGjx6t1q1bq3Hjxvrss89KqlYAAAAAcAiWgtTChQs1dOhQeXl55evz9vbWM888o/nz5xdbcQAAAADgiCwFqS+//FKdO3cusP/hhx9WfHz8TRcFAAAAAI7MUpA6f/78NW97nsfZ2Vk//vjjTRcFAAAAAI7MUpCqWbOmjhw5UmD/V199pRo1atx0UQAAAADgyCzdta9r166aPHmyOnfunO8Lb3/99VdNnTpV3bt3L9YCAQAAUD61fH5VWZeA20T860+X+jYtBamXX35Z69at05133qlRo0apQYMGkqRvv/1WS5cuVU5Ojl566aUSKRQAAAAAHIWlIOXn56d9+/bp2Wef1aRJk2QYhiTJZrMpIiJCS5culZ+fX4kUCgAAAACOwvIX8gYFBWnz5s36+eeflZSUJMMwVL9+fVWpUqUk6gMAAAAAh2M5SOWpUqWKWrduXZy1AAAAAEC5YOmufQAAAAAAghQAAAAAWEaQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFjl8kPrhhx/0pz/9SVWrVpW7u7uaNGmiQ4cOmf2GYWjKlCmqUaOG3N3dFR4eruPHj5dhxQAAAABudQ4dpH7++We1bdtWLi4u2rJli7755hvNmzdPVapUMcfMmTNHixcv1rJly3TgwAF5eHgoIiJCly9fLsPKAQAAANzKnMu6gOuZPXu2AgMDFR0dbbaFhISY/zYMQwsXLtTLL7+sXr16SZJWrVolPz8/bdiwQZGRkaVeMwAAAIBbn0Mfkdq4caNatWqlxx9/XNWrV1eLFi20fPlysz85OVkpKSkKDw8327y9vdWmTRvFxcUVOG9WVpYyMjLsFgAAAAAoLIcOUt99953efPNN1a9fX//+97/17LPPasyYMVq5cqUkKSUlRZLk5+dn9zg/Pz+z71pmzZolb29vcwkMDCy5nQAAAABwy3HoIJWbm6u7775bM2fOVIsWLTRs2DANHTpUy5Ytu6l5J02apPT0dHM5c+ZMMVUMAAAA4Hbg0EGqRo0aatSokV1baGioTp8+LUny9/eXJJ0/f95uzPnz582+a3F1dZWXl5fdAgAAAACF5dBBqm3btjp27Jhd23//+18FBQVJ+u3GE/7+/oqNjTX7MzIydODAAYWFhZVqrQAAAABuHw59175x48bpvvvu08yZM9W3b1998cUXevvtt/X2229Lkmw2m6KiovTqq6+qfv36CgkJ0eTJkxUQEKDevXuXbfEAAAAAblkOHaRat26t9evXa9KkSZo+fbpCQkK0cOFC9evXzxzzwgsv6NKlSxo2bJjS0tLUrl07xcTEyM3NrQwrBwAAAHArc+ggJUndu3dX9+7dC+y32WyaPn26pk+fXopVAQAAALidOfQ1UgAAAADgiAhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACAReUqSL322muy2WyKiooy2y5fvqyRI0eqatWq8vT0VJ8+fXT+/PmyKxIAAADALa/cBKmDBw/qrbfeUtOmTe3ax40bp08++UQffvihdu/erbNnz+rRRx8toyoBAAAA3A7KRZDKzMxUv379tHz5clWpUsVsT09P1z/+8Q/Nnz9fHTt2VMuWLRUdHa19+/Zp//79ZVgxAAAAgFtZuQhSI0eOVLdu3RQeHm7XHh8fr+zsbLv2hg0bqnbt2oqLiytwvqysLGVkZNgtAAAAAFBYzmVdwI289957Onz4sA4ePJivLyUlRRUrVpSPj49du5+fn1JSUgqcc9asWXrllVeKu1QAAAAAtwmHPiJ15swZjR07VmvWrJGbm1uxzTtp0iSlp6eby5kzZ4ptbgAAAAC3PocOUvHx8UpNTdXdd98tZ2dnOTs7a/fu3Vq8eLGcnZ3l5+enK1euKC0tze5x58+fl7+/f4Hzurq6ysvLy24BAAAAgMJy6FP7OnXqpK+//tqubdCgQWrYsKEmTpyowMBAubi4KDY2Vn369JEkHTt2TKdPn1ZYWFhZlAwAAADgNuDQQapy5cq666677No8PDxUtWpVs33w4MEaP368fH195eXlpdGjRyssLEz33ntvWZQMAAAA4Dbg0EGqMBYsWCAnJyf16dNHWVlZioiI0BtvvFHWZQEAAAC4hZW7ILVr1y67dTc3Ny1dulRLly4tm4IAAAAA3HYc+mYTAAAAAOCICFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsMjhg9SsWbPUunVrVa5cWdWrV1fv3r117NgxuzGXL1/WyJEjVbVqVXl6eqpPnz46f/58GVUMAAAA4Fbn8EFq9+7dGjlypPbv369t27YpOztbDz/8sC5dumSOGTdunD755BN9+OGH2r17t86ePatHH320DKsGAAAAcCtzLusCbiQmJsZufcWKFapevbri4+P1wAMPKD09Xf/4xz+0du1adezYUZIUHR2t0NBQ7d+/X/fee2++ObOyspSVlWWuZ2RklOxOAAAAALilOPwRqT9KT0+XJPn6+kqS4uPjlZ2drfDwcHNMw4YNVbt2bcXFxV1zjlmzZsnb29tcAgMDS75wAAAAALeMchWkcnNzFRUVpbZt2+quu+6SJKWkpKhixYry8fGxG+vn56eUlJRrzjNp0iSlp6eby5kzZ0q6dAAAAAC3EIc/te/3Ro4cqSNHjmjv3r03NY+rq6tcXV2LqSoAAAAAt5tyc0Rq1KhR+vTTT7Vz507VqlXLbPf399eVK1eUlpZmN/78+fPy9/cv5SoBAAAA3A4cPkgZhqFRo0Zp/fr12rFjh0JCQuz6W7ZsKRcXF8XGxpptx44d0+nTpxUWFlba5QIAAAC4DTj8qX0jR47U2rVr9a9//UuVK1c2r3vy9vaWu7u7vL29NXjwYI0fP16+vr7y8vLS6NGjFRYWds079gEAAADAzXL4IPXmm29Kktq3b2/XHh0drYEDB0qSFixYICcnJ/Xp00dZWVmKiIjQG2+8UcqVAgAAALhdOHyQMgzjhmPc3Ny0dOlSLV26tBQqAgAAAHC7c/hrpAAAAADA0RCkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAAAGARQQoAAAAALCJIAQAAAIBFBCkAAAAAsIggBQAAAAAWEaQAAAAAwCKCFAAAAABYRJACAAAAAIsIUgAAAABgEUEKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAi26ZILV06VIFBwfLzc1Nbdq00RdffFHWJQEAAAC4Rd0SQer999/X+PHjNXXqVB0+fFjNmjVTRESEUlNTy7o0AAAAALegWyJIzZ8/X0OHDtWgQYPUqFEjLVu2TJUqVdI777xT1qUBAAAAuAU5l3UBN+vKlSuKj4/XpEmTzDYnJyeFh4crLi7umo/JyspSVlaWuZ6eni5JysjIKJaacrJ+LZZ5gBsprt/ZksDrAKWF1wHguK8DXgMoLcX5GsibyzCM646zGTca4eDOnj2rmjVrat++fQoLCzPbX3jhBe3evVsHDhzI95hp06bplVdeKc0yAQAAAJQjZ86cUa1atQrsL/dHpIpi0qRJGj9+vLmem5urCxcuqGrVqrLZbGVY2e0rIyNDgYGBOnPmjLy8vMq6HKDU8RoAeB0AEq8DR2AYhi5evKiAgIDrjiv3QeqOO+5QhQoVdP78ebv28+fPy9/f/5qPcXV1laurq12bj49PSZUIC7y8vPijgdsarwGA1wEg8Tooa97e3jccU+5vNlGxYkW1bNlSsbGxZltubq5iY2PtTvUDAAAAgOJS7o9ISdL48eM1YMAAtWrVSvfcc48WLlyoS5cuadCgQWVdGgAAAIBb0C0RpJ544gn9+OOPmjJlilJSUtS8eXPFxMTIz8+vrEtDIbm6umrq1Kn5TrkEbhe8BgBeB4DE66A8Kfd37QMAAACA0lbur5ECAAAAgNJGkAIAAAAAiwhSAAAAAGARQQpF0r59e0VFRZV1GcAtZdq0aWrevHlZlwEAuAUFBwdr4cKFZV3GLYUgBQAAADgYPrR2fAQpAABQLl25cqWsSwDKlGEYunr1almXcdsiSKHIcnNz9cILL8jX11f+/v6aNm2a2Td//nw1adJEHh4eCgwM1IgRI5SZmWn2r1ixQj4+PtqwYYPq168vNzc3RURE6MyZM+aYvNOc3nrrLQUGBqpSpUrq27ev0tPTJUl79uyRi4uLUlJS7OqKiorS/fffX7I7DxQgNzdXc+bMUb169eTq6qratWtrxowZkqSJEyfqzjvvVKVKlVSnTh1NnjxZ2dnZBc41cOBA9e7dWzNnzpSfn598fHw0ffp0Xb16Vc8//7x8fX1Vq1YtRUdHl9buAQWKiYlRu3bt5OPjo6pVq6p79+46ceKEJOnkyZOy2Wxat26dOnTooEqVKqlZs2aKi4uzm2P58uXm3/tHHnlE8+fPl4+Pj9mf9//C3//+d4WEhMjNzU2rVq1S1apVlZWVZTdX79691b9//xLfb9ye2rdvrzFjxhT4PigtLU1DhgxRtWrV5OXlpY4dO+rLL780+/P+vv9eVFSU2rdvb/bv3r1bixYtks1mk81m08mTJ7Vr1y7ZbDZt2bJFLVu2lKurq/bu3asTJ06oV69e8vPzk6enp1q3bq3t27eXwjNxeyNIochWrlwpDw8PHThwQHPmzNH06dO1bds2SZKTk5MWL16so0ePauXKldqxY4deeOEFu8f/8ssvmjFjhlatWqXPP/9caWlpioyMtBuTlJSkDz74QJ988oliYmL0n//8RyNGjJAkPfDAA6pTp45Wr15tjs/OztaaNWv05z//uYT3Hri2SZMm6bXXXtPkyZP1zTffaO3ateaXg1euXFkrVqzQN998o0WLFmn58uVasGDBdefbsWOHzp49qz179mj+/PmaOnWqunfvripVqujAgQMaPny4nnnmGX3//felsXtAgS5duqTx48fr0KFDio2NlZOTkx555BHl5uaaY1566SU999xzSkhI0J133qknn3zS/DT9888/1/DhwzV27FglJCTooYceMj+E+L2kpCR9/PHHWrdunRISEvT4448rJydHGzduNMekpqZq06ZN/F+AEnW990GPP/64UlNTtWXLFsXHx+vuu+9Wp06ddOHChULNvWjRIoWFhWno0KE6d+6czp07p8DAQLP/xRdf1GuvvabExEQ1bdpUmZmZ6tq1q2JjY/Wf//xHnTt3Vo8ePXT69OkS2Xf8fwZQBA8++KDRrl07u7bWrVsbEydOvOb4Dz/80Khataq5Hh0dbUgy9u/fb7YlJiYakowDBw4YhmEYU6dONSpUqGB8//335pgtW7YYTk5Oxrlz5wzDMIzZs2cboaGhZv/HH39seHp6GpmZmTe/k4BFGRkZhqurq7F8+fJCjX/99deNli1bmutTp041mjVrZq4PGDDACAoKMnJycsy2Bg0aGPfff7+5fvXqVcPDw8N49913b34HgGL0448/GpKMr7/+2khOTjYkGX//+9/N/qNHjxqSjMTERMMwDOOJJ54wunXrZjdHv379DG9vb3N96tSphouLi5Gammo37tlnnzW6dOlirs+bN8+oU6eOkZubWwJ7Blz/fdBnn31meHl5GZcvX7brr1u3rvHWW28ZhvHb3/devXrZ9Y8dO9Z48MEH7bYxduxYuzE7d+40JBkbNmy4YY2NGzc2lixZYq4HBQUZCxYsuPHOodA4IoUia9q0qd16jRo1lJqaKknavn27OnXqpJo1a6py5crq37+/fvrpJ/3yyy/meGdnZ7Vu3dpcb9iwoXx8fJSYmGi21a5dWzVr1jTXw8LClJubq2PHjkn67dB3UlKS9u/fL+m3Uwb79u0rDw+P4t9h4AYSExOVlZWlTp06XbP//fffV9u2beXv7y9PT0+9/PLLN/y0sHHjxnJy+r8/1X5+fmrSpIm5XqFCBVWtWtV87QFl5fjx43ryySdVp04deXl5KTg4WJLsfsd///9GjRo1JMn83T127Jjuueceuzn/uC5JQUFBqlatml3b0KFDtXXrVv3www+Sfvu/YODAgbLZbDe/Y0ABCnof9OWXXyozM1NVq1aVp6enuSQnJ5unu96sVq1a2a1nZmbqueeeU2hoqHx8fOTp6anExESOSJUw57IuAOWXi4uL3brNZlNubq5Onjyp7t2769lnn9WMGTPk6+urvXv3avDgwbpy5YoqVapUbDVUr15dPXr0UHR0tEJCQrRlyxbt2rWr2OYHrHB3dy+wLy4uTv369dMrr7yiiIgIeXt767333tO8efOuO+e1XmcFvfaAstSjRw8FBQVp+fLlCggIUG5uru666y67G0L8/nc3L+RY/d291gdlLVq0ULNmzbRq1So9/PDDOnr0qDZt2lTEPQEKp6C/xZmZmapRo8Y134/kXfPn5OQkwzDs+q53zewf/fF18Nxzz2nbtm2aO3eu6tWrJ3d3dz322GPckKWEEaRQ7OLj45Wbm6t58+aZn6R/8MEH+cZdvXpVhw4dMj9xPHbsmNLS0hQaGmqOOX36tM6ePauAgABJ0v79++Xk5KQGDRqYY4YMGaInn3xStWrVUt26ddW2bduS3D2gQPXr15e7u7tiY2M1ZMgQu759+/YpKChIL730ktl26tSp0i4RKBE//fSTjh07puXLl5s3+9m7d6+lORo0aKCDBw/atf1x/XqGDBmihQsX6ocfflB4eLjd9SRAabr77ruVkpIiZ2dn88jsH1WrVk1Hjhyxa0tISLALZxUrVlROTk6htvn5559r4MCBeuSRRyT9doTq5MmTRaofhcepfSh29erVU3Z2tpYsWaLvvvtOq1ev1rJly/KNc3Fx0ejRo3XgwAHFx8dr4MCBuvfee+1O5XBzc9OAAQP05Zdf6rPPPtOYMWPUt29f+fv7m2MiIiLk5eWlV199VYMGDSqVfQSuxc3NTRMnTtQLL7ygVatW6cSJE9q/f7/+8Y9/qH79+jp9+rTee+89nThxQosXL9b69evLumSgWFSpUkVVq1bV22+/raSkJO3YsUPjx4+3NMfo0aO1efNmzZ8/X8ePH9dbb72lLVu2FPr0vKeeekrff/+9li9fzk0mUKbCw8MVFham3r17a+vWrTp58qT27dunl156SYcOHZIkdezYUYcOHdKqVat0/PhxTZ06NV+wCg4O1oEDB3Ty5En973//u+7R2/r165s3YPnyyy/11FNPcaZCKSBIodg1a9ZM8+fP1+zZs3XXXXdpzZo1mjVrVr5xlSpV0sSJE/XUU0+pbdu28vT01Pvvv283pl69enr00UfVtWtXPfzww2ratKneeOMNuzFOTk4aOHCgcnJy9PTTT5fovgE3MnnyZE2YMEFTpkxRaGionnjiCaWmpqpnz54aN26cRo0apebNm2vfvn2aPHlyWZcLFAsnJye99957io+P11133aVx48bp9ddftzRH27ZttWzZMs2fP1/NmjVTTEyMxo0bJzc3t0I93tvbW3369JGnp2e+20oDpclms2nz5s164IEHNGjQIN15552KjIzUqVOnzLu4RkREaPLkyXrhhRfUunVrXbx4Md97mOeee04VKlRQo0aNVK1atete7zR//nxVqVJF9913n3r06KGIiAjdfffdJbqfkGzGH0/QBErBihUrFBUVpbS0tALHTJs2TRs2bFBCQsIN5xs8eLB+/PFHu9vfAgDKt6FDh+rbb7/VZ599VqjxnTp1UuPGjbV48eISrgwAuEYK5Vx6erq+/vprrV27lhAFAOXc3Llz9dBDD8nDw0NbtmzRypUr852FcC0///yzdu3apV27dhVqPAAUB4IUyrVevXrpiy++0PDhw/XQQw+VdTkAgJvwxRdfaM6cObp48aLq1KmjxYsX57txy7W0aNFCP//8s2bPnm13MyIAKEmc2gcAAAAAFnGzCQAAAACwiCAFAAAAABYRpAAAAADAIoIUAAAAAFhEkAIAAAAAiwhSAAAUYNq0aWrevHlZlwEAcEAEKQCAQxk4cKBsNlu+pXPnziW6XZvNpg0bNti1Pffcc4qNjS3R7QIAyie+kBcA4HA6d+6s6OhouzZXV9dSr8PT01Oenp6lvl0AgOPjiBQAwOG4urrK39/fbqlSpYqk344cvfXWW+revbsqVaqk0NBQxcXFKSkpSe3bt5eHh4fuu+8+nThxwm7ON998U3Xr1lXFihXVoEEDrV692uwLDg6WJD3yyCOy2Wzm+h9P7cvNzdX06dNVq1Ytubq6qnnz5oqJiTH7T548KZvNpnXr1qlDhw6qVKmSmjVrpri4OHPMqVOn1KNHD1WpUkUeHh5q3LixNm/eXMzPIACgpBGkAADlzl//+lc9/fTTSkhIUMOGDfXUU0/pmWee0aRJk3To0CEZhqFRo0aZ49evX6+xY8dqwoQJOnLkiJ555hkNGjRIO3fulCQdPHhQkhQdHa1z586Z63+0aNEizZs3T3PnztVXX32liIgI9ezZU8ePH7cb99JLL+m5555TQkKC7rzzTj355JO6evWqJGnkyJHKysrSnj179PXXX2v27Nkc9QKA8sgAAMCBDBgwwKhQoYLh4eFht8yYMcMwDMOQZLz88svm+Li4OEOS8Y9//MNse/fddw03Nzdz/b777jOGDh1qt53HH3/c6Nq1q7kuyVi/fr3dmKlTpxrNmjUz1wMCAsw68rRu3doYMWKEYRiGkZycbEgy/v73v5v9R48eNSQZiYmJhmEYRpMmTYxp06ZZeUoAAA6II1IAAIfToUMHJSQk2C3Dhw83+5s2bWr+28/PT5LUpEkTu7bLly8rIyNDkpSYmKi2bdvabaNt27ZKTEwsdE0ZGRk6e/Zsoeb5fX01atSQJKWmpkqSxowZo1dffVVt27bV1KlT9dVXXxW6BgCA4yBIAQAcjoeHh+rVq2e3+Pr6mv0uLi7mv202W4Ftubm5pVSxvevVMmTIEH333Xfq37+/vv76a7Vq1UpLliwpkzoBAEVHkAIA3PJCQ0P1+eef27V9/vnnatSokbnu4uKinJycAufw8vJSQEDADecpjMDAQA0fPlzr1q3ThAkTtHz5ckuPBwCUPW5/DgBwOFlZWUpJSbFrc3Z21h133FGk+Z5//nn17dtXLVq0UHh4uD755BOtW7dO27dvN8cEBwcrNjZWbdu2laurq3mXwD/OM3XqVNWtW1fNmzdXdHS0EhIStGbNmkLXEhUVpS5duujOO+/Uzz//rJ07dyo0NLRI+wUAKDsEKQCAw4mJiTGvLcrToEEDffvtt0War3fv3lq0aJHmzp2rsWPHKiQkRNHR0Wrfvr05Zt68eRo/fryWL1+umjVr6uTJk/nmGTNmjNLT0zVhwgSlpqaqUaNG2rhxo+rXr1/oWnJycjRy5Eh9//338vLyUufOnbVgwYIi7RcAoOzYDMMwyroIAAAAAChPuEYKAAAAACwiSAEAAACARQQpAAAAALCIIAUAAAAAFhGkAAAAAMAighQAAAAAWESQAgAAAACLCFIAAAAAYBFBCgAAAAAsIkgBAAAAgEUEKQAAAACw6P8BuZGgzOFzRwEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3 Visualize emotions distribution \n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=emotion_counts.index, y=emotion_counts.values)\n",
    "plt.title('Distribution of Emotions in Training Set')\n",
    "plt.xlabel('Emotions')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch parameters\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.001, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(500,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Creating a GridSearchCV object\n",
    "clf = GridSearchCV(model, param_grid, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate=&#x27;adaptive&#x27;, max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50,), (100,), (150,)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate=&#x27;adaptive&#x27;, max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50,), (100,), (150,)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, batch_size=256, hidden_layer_sizes=(500,),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, batch_size=256, hidden_layer_sizes=(500,),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate='adaptive', max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'], 'alpha': [0.001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model with clf\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (150,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Printing best parameter found.\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the best parameter found. \n",
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.78703704 0.74074074 0.71962617 0.76635514 0.75700935]\n",
      "Mean cross-validation score: 0.7541536863966771\n"
     ]
    }
   ],
   "source": [
    "#Cross validation before smote\n",
    "cross_val_scores = cross_val_score(best_model, x_train, y_train, cv=5)\n",
    "print(f'Cross-validation scores: {cross_val_scores}')\n",
    "print(f'Mean cross-validation score: {cross_val_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report without SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.82      0.82      0.82        38\n",
      "        calm       0.73      0.71      0.72        38\n",
      "       happy       0.77      0.73      0.75        37\n",
      "     neutral       0.52      0.59      0.55        22\n",
      "\n",
      "    accuracy                           0.73       135\n",
      "   macro avg       0.71      0.71      0.71       135\n",
      "weighted avg       0.73      0.73      0.73       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evulate the model\n",
    "grid_predictions = best_model.predict(x_test)\n",
    "print(\"Report without SMOTE:\")\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=80)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy      155\n",
      "neutral    155\n",
      "calm       155\n",
      "angry      155\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify distribution after applying SMOTE\n",
    "resampled_counts = pd.Series(y_train_resampled).value_counts()\n",
    "print(resampled_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate=&#x27;adaptive&#x27;, max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50,), (100,), (150,)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate=&#x27;adaptive&#x27;, max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.05],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(50,), (100,), (150,)],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, batch_size=256, hidden_layer_sizes=(500,),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, batch_size=256, hidden_layer_sizes=(500,),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=500)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(alpha=0.001, batch_size=256,\n",
       "                                     hidden_layer_sizes=(500,),\n",
       "                                     learning_rate='adaptive', max_iter=500),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'], 'alpha': [0.001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Fitting the model with clf\n",
    "clf.fit(x_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model_smote = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.84677419 0.77419355 0.77419355 0.87903226 0.87903226]\n",
      "Mean cross-validation score: 0.8306451612903226\n"
     ]
    }
   ],
   "source": [
    "# Cross validation after smote \n",
    "cross_val_scores_smote = cross_val_score(best_model_smote, x_train_resampled, y_train_resampled, cv=5)\n",
    "print(f'Cross-validation scores: {cross_val_scores_smote}')\n",
    "print(f'Mean cross-validation score: {cross_val_scores_smote.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.85      0.87      0.86        38\n",
      "        calm       0.84      0.82      0.83        38\n",
      "       happy       0.81      0.81      0.81        37\n",
      "     neutral       0.73      0.73      0.73        22\n",
      "\n",
      "    accuracy                           0.81       135\n",
      "   macro avg       0.81      0.81      0.81       135\n",
      "weighted avg       0.81      0.81      0.81       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model after using SMOTE\n",
    "\n",
    "grid_predictions_smote = best_model_smote.predict(x_test)\n",
    "print(\"Report with SMOTE:\")\n",
    "print(classification_report(y_test, grid_predictions_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best model\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with optimized hyperparameters: 0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "# Printing accuracy \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with optimized hyperparameters: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.48%\n"
     ]
    }
   ],
   "source": [
    "# DataFlair - Calculating accuracy \n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# DataFlair - printing accuracy \n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_2024-07.pkl']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# saving the model\n",
    "joblib.dump(clf, \"./model_2024-07.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'happy', 'happy', 'happy', 'neutral', 'calm', 'calm',\n",
       "       'happy', 'angry', 'calm', 'happy', 'calm', 'angry', 'calm',\n",
       "       'happy', 'angry', 'calm', 'calm', 'angry', 'calm', 'calm', 'happy',\n",
       "       'happy', 'happy', 'calm', 'angry', 'angry', 'happy', 'neutral',\n",
       "       'angry', 'calm', 'calm', 'neutral', 'happy', 'happy', 'calm',\n",
       "       'angry', 'happy', 'calm', 'happy', 'calm', 'angry', 'calm',\n",
       "       'happy', 'calm', 'calm', 'angry', 'calm', 'calm', 'happy', 'angry',\n",
       "       'angry', 'calm', 'neutral', 'calm', 'neutral', 'angry', 'neutral',\n",
       "       'neutral', 'happy', 'angry', 'happy', 'angry', 'neutral',\n",
       "       'neutral', 'happy', 'angry', 'calm', 'happy', 'happy', 'happy',\n",
       "       'angry', 'calm', 'angry', 'calm', 'calm', 'happy', 'neutral',\n",
       "       'neutral', 'neutral', 'angry', 'calm', 'calm', 'calm', 'neutral',\n",
       "       'calm', 'angry', 'neutral', 'angry', 'angry', 'angry', 'happy',\n",
       "       'angry', 'happy', 'neutral', 'happy', 'neutral', 'happy', 'angry',\n",
       "       'calm', 'neutral', 'calm', 'happy', 'angry', 'angry', 'neutral',\n",
       "       'angry', 'happy', 'calm', 'calm', 'happy', 'happy', 'happy',\n",
       "       'angry', 'angry', 'neutral', 'happy', 'happy', 'angry', 'calm',\n",
       "       'angry', 'angry', 'angry', 'angry', 'calm', 'happy', 'calm',\n",
       "       'neutral', 'angry', 'angry', 'happy', 'angry', 'angry', 'neutral',\n",
       "       'happy'], dtype='<U7')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# testing the model\n",
    "clf = joblib.load(\"./model_2024-07.pkl\") \n",
    "\n",
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
